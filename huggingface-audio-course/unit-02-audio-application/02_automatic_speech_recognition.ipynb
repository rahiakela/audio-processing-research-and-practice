{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOuhGH2yAgC5Q3JbIVYRqJb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/audio-processing-research-and-practice/blob/main/huggingface-audio-course/unit-02-audio-application/02_automatic_speech_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "CnSDLCsqHQ5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reference**:\n",
        "\n",
        "[Audio classification with a pipeline](https://huggingface.co/learn/audio-course/chapter2/audio_classification_pipeline)"
      ],
      "metadata": {
        "id": "KbPVpz79MjbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets[audio]"
      ],
      "metadata": {
        "id": "F7YnGsIkHREn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from datasets import Audio\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "from transformers import WhisperFeatureExtractor\n",
        "from transformers import AutoProcessor\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display"
      ],
      "metadata": {
        "id": "uj-xeNFDHVfT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset"
      ],
      "metadata": {
        "id": "sGrmWoH3Haoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "minds = load_dataset(\"PolyAI/minds14\", name=\"en-AU\", split=\"train\")\n",
        "minds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPlC_Yu_Hb1d",
        "outputId": "00c00489-3327-4b29-f66b-9c40abb339c4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
              "    num_rows: 654\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let’s take a closer look at one of the examples\n",
        "example = minds[0]\n",
        "example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY9QrRSwH6y3",
        "outputId": "388ffad2-b258-4d34-a919-aa74f28a51eb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'path': '/root/.cache/huggingface/datasets/downloads/extracted/a19fbc5032eacf25eab0097832db7b7f022b42104fbad6bd5765527704a428b9/en-AU~PAY_BILL/response_4.wav',\n",
              " 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/a19fbc5032eacf25eab0097832db7b7f022b42104fbad6bd5765527704a428b9/en-AU~PAY_BILL/response_4.wav',\n",
              "  'array': array([ 0.        ,  0.00024414, -0.00024414, ..., -0.00024414,\n",
              "          0.00024414,  0.0012207 ]),\n",
              "  'sampling_rate': 8000},\n",
              " 'transcription': 'I would like to pay my electricity bill using my card can you please assist',\n",
              " 'english_transcription': 'I would like to pay my electricity bill using my card can you please assist',\n",
              " 'intent_class': 13,\n",
              " 'lang_id': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resampling audio data\n",
        "minds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
        "minds[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Sa3M5N8XJs9",
        "outputId": "41c0383b-6b25-4380-a578-6a34b1b05b38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'path': '/root/.cache/huggingface/datasets/downloads/extracted/a19fbc5032eacf25eab0097832db7b7f022b42104fbad6bd5765527704a428b9/en-AU~PAY_BILL/response_4.wav',\n",
              " 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/a19fbc5032eacf25eab0097832db7b7f022b42104fbad6bd5765527704a428b9/en-AU~PAY_BILL/response_4.wav',\n",
              "  'array': array([2.36119668e-05, 1.92324660e-04, 2.19284790e-04, ...,\n",
              "         9.40907281e-04, 1.16613181e-03, 7.20883254e-04]),\n",
              "  'sampling_rate': 16000},\n",
              " 'transcription': 'I would like to pay my electricity bill using my card can you please assist',\n",
              " 'english_transcription': 'I would like to pay my electricity bill using my card can you please assist',\n",
              " 'intent_class': 13,\n",
              " 'lang_id': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ASR pipeline"
      ],
      "metadata": {
        "id": "JbgE3n98IzE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "asr = pipeline(\"automatic-speech-recognition\")"
      ],
      "metadata": {
        "id": "2zDl6pa2I5Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, we’ll take an example from the dataset and pass its raw data to the pipeline\n",
        "example = minds[0]\n",
        "\n",
        "asr(example[\"audio\"][\"array\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEc9a4GYJRF0",
        "outputId": "e7ffa369-b09a-4ff9-baae-70ac68bd590c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'I WOULD LIKE TO PAY MY ELECTRICITY BILL USING MY CAD CAN YOU PLEASE ASSIST'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let’s compare this output to what the actual transcription\n",
        "example[\"english_transcription\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RKpg2iv_Jthu",
        "outputId": "6fcb75e4-1995-454c-d4ec-643f4573913b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I would like to pay my electricity bill using my card can you please assist'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s try this for the German split of the MINDS-14."
      ],
      "metadata": {
        "id": "HyPgmpCYYQtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "minds = load_dataset(\"PolyAI/minds14\", name=\"de-DE\", split=\"train\")\n",
        "minds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))"
      ],
      "metadata": {
        "id": "0g7d04YaYRRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = minds[0]\n",
        "example[\"transcription\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UNn-g_6vYY6x",
        "outputId": "fbe5dcd7-b04f-4371-8334-e6414b76a498"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ich möchte gerne Geld auf mein Konto einzahlen'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "asr = pipeline(\"automatic-speech-recognition\", model=\"maxidl/wav2vec2-large-xlsr-german\")"
      ],
      "metadata": {
        "id": "iYmxxM1LYgHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asr(example[\"audio\"][\"array\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoNusKXHYklD",
        "outputId": "0bc4999c-bc2d-4eb6-c457-e0d85edc1aab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'ich möchte gerne geld auf mein konto einzallen'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}