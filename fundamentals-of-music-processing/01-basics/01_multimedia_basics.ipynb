{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOr1pvMiiOtQ/fGdF1yA66X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/audio-processing-research-and-practice/blob/main/fundamentals-of-music-processing/01-basics/01_multimedia_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multimedia Basics"
      ],
      "metadata": {
        "id": "WZyxW45IgYxn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "In this notebook, we give a short overview on how to integrate multimedia objects (in particular, audio, image, and video objects) into a Jupyter notebook. Rather than being comprehensive, we only give a selection of possibilities as used in the other FMP notebooks. In particular, we discuss two alternatives: a direct integration of images, video, and audio elements using HTML tags as well as an integration using the module <code>IPython.display</code>.\n",
        "</p>\n",
        "\n",
        "**Reference**\n",
        "\n",
        "[Basics](https://www.audiolabs-erlangen.de/resources/MIR/FMP/B/B.html)\n",
        "\n",
        "[Multimedia Basics](https://www.audiolabs-erlangen.de/resources/MIR/FMP/B/B_Multimedia.html)"
      ],
      "metadata": {
        "id": "EY6DPaMbgdEO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "mYLbm-a7hAmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Qnym1uShhBwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/rahiakela/audio-processing-research-and-practice/raw/main/fundamentals-of-music-processing/01-basics/data/data.zip\n",
        "\n",
        "!unzip data.zip\n",
        "!rm -rf data.zip"
      ],
      "metadata": {
        "id": "vsoo7baAgdQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audio Objects"
      ],
      "metadata": {
        "id": "x9ned26_l-zu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Audio: HTML `<audio>` tag**\n",
        "\n",
        "The HTML `<audio>` tag defines an in-browser audio player and allows for playing back a specified audio file (MP3, WAV, OGG), see [here](https://www.w3schools.com/Tags/tag_audio.asp) for details. Note that the functionality and the visual appearance of the audio player depends on the respective browser used. The `<audio>` tag can be used within a markdown cell and does not require any Python. \n",
        "\n",
        "<audio src=\"../data/B/FMP_B_Note-C4_Piano.mp3\" type=\"audio/mpeg\" controls=\"controls\"></audio>"
      ],
      "metadata": {
        "id": "9QTUghbal_jg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Audio: Using  <code>IPython.display.Audio</code>"
      ],
      "metadata": {
        "id": "aANDYhL3mS_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An alternative is to use the module <code>IPython.display</code>, which is an application programming interface (API) for displaying various tools in IPython. As for audio, the following class is available ([`IPython` version 6.0 or higher](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html)):\n",
        "\n",
        "`IPython.display.Audio(data=None, filename=None, url=None, embed=None, rate=None, autoplay=False, normalize=True, *, element_id=None)`\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "<strong>Warning:</strong> As default, <code>IPython.display.Audio</code> normalizes the audio (dividing by the maximum over all sample values) before playback. This may be unwanted for certain applications, where the volume of the audio should be kept to its original level. For examples, see the <a href=\"../B/B_PythonAudio.html\">FMP notebook on Audio</a>.\n",
        "</div> \n",
        "\n",
        "When used in a code cell, <code>IPython.display.audio</code> creates an in-browser audio player. The following two options are conceptually different: \n",
        "\n",
        "* When using the keyword argument `filename`, the audio file is loaded from the specified path and **embedded** into the notebook (with default `embed=True`). \n",
        "* When using the keyword argument `url`, the player is **linked** to the audio file by the specified URL (with default `embed=False`). \n",
        "\n",
        "Note that if you want the audio to be playable later with no internet connection (or with no local audio file available), you need to embed the audio file into the notebook. This can be done using the first option. The following example illustrates the difference between the two options. "
      ],
      "metadata": {
        "id": "VD7AVjywmT9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_filename = os.path.join(\".\", \"data\", \"FMP_B_Note-C4_Piano.mp3\")\n",
        "\n",
        "audio_element_filename = ipd.Audio(filename=path_filename)\n",
        "print(f\"Size of <audio> tag (with embedded audio file): {len(audio_element_filename._repr_html_().encode('utf8'))} Bytes\")\n",
        "ipd.display(audio_element_filename)\n",
        "\n",
        "audio_element_url = ipd.Audio(filename=path_filename)\n",
        "print(f\"Size of <audio> tag (with embedded audio file): {len(audio_element_url._repr_html_().encode('utf8'))} Bytes\")\n",
        "ipd.display(audio_element_url)"
      ],
      "metadata": {
        "id": "xK-oTJuomXA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Audio: WAV and MP3"
      ],
      "metadata": {
        "id": "ENP-ZFPCzUmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding audio files may lead to very large Jupyter notebooks (also large files when exported as HTML). This particularly holds when embedding raw audio files encoded as WAV file. \n",
        "\n",
        "For example, encoding a song of five to ten minutes in CD quality (44100 Hz, stereo), may easily lead to a file size of more than 50 MB. \n",
        "\n",
        "Therefore, to reduce the size, one may consider the following:\n",
        "\n",
        "* Trim audio files to have short durations.\n",
        "* Reduce the sampling rate.\n",
        "* Convert to mono. \n",
        "* Use the MP3 audio coding format.\n",
        "\n",
        "The following example shows the difference in file size of a WAV and MP3 audio file."
      ],
      "metadata": {
        "id": "BOUVp_r-zVBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_filename_wav = os.path.join(\".\", \"data\", \"FMP_B_Note-C4_Piano.wav\")\n",
        "\n",
        "audio_element_wav = ipd.Audio(filename=path_filename_wav)\n",
        "print(f\"Size of <audio> tag (with embedded WAV file): {len(audio_element_wav._repr_html_().encode('utf8'))} Bytes\")\n",
        "ipd.display(audio_element_wav)\n",
        "\n",
        "path_filename_mp3 = os.path.join(\".\", \"data\", \"FMP_B_Note-C4_Piano.mp3\")\n",
        "audio_element_mp3 = ipd.Audio(filename=path_filename_mp3)\n",
        "print(f\"Size of <audio> tag (with embedded MP3 file): {len(audio_element_mp3._repr_html_().encode('utf8'))} Bytes\")\n",
        "ipd.display(audio_element_mp3)"
      ],
      "metadata": {
        "id": "I4HguJG3zXeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Audio: Waveform-Based Signals"
      ],
      "metadata": {
        "id": "IgPf4QwD1PJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One may also use `IPython.display.Audio` to embed waveform-based audio signals (either mono or stereo). \n",
        "\n",
        "The following code example shows how to read a WAV and MP3 file using the Python package `librosa`. \n",
        "\n",
        "Note that in both cases, the audio files are converted into waveform representations."
      ],
      "metadata": {
        "id": "omZqlVlm1PkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_wav, fs_wav = librosa.load(path_filename_wav, sr=None)\n",
        "audio_wav = ipd.Audio(data=x_wav, rate=fs_wav)\n",
        "print(f\"Size of <audio> tag (coming from WAV): {len(audio_wav._repr_html_().encode('utf8'))} Bytes\")\n",
        "ipd.display(audio_wav)\n",
        "\n",
        "x_mp3, fs_mp3 = librosa.load(path_filename_mp3, sr=None)\n",
        "audio_mp3 = ipd.Audio(data=x_mp3, rate=fs_mp3)\n",
        "print(f\"Size of <audio> tag (coming from MP3): {len(audio_mp3._repr_html_().encode('utf8'))} Bytes\")\n",
        "ipd.display(audio_mp3)"
      ],
      "metadata": {
        "id": "jF_Egi3g1S9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next example shows how to generate a stereo audio signal and how to embed it into the Jupyter notebook. \n",
        "\n",
        "For explanations of the code example, we refer to the [FMP notebook on waveforms](../C1/C1S3_Waveform.html).\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "<strong>Warning:</strong> Depending on the web browser, only specific sampling rates may be supported for audio playback. In the following example, we use the sampling rate <code>Fs = 4000</code>, which seems to work for most browsers. \n",
        "</div> "
      ],
      "metadata": {
        "id": "m9_LGRcd25qM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fs = 4000\n",
        "duration = 4\n",
        "t = np.linspace(0, duration, fs * duration)\n",
        "signal_left = np.sin(2 * np.pi * 200 * t)\n",
        "signal_right = np.sin(2 * np.pi * 600 * t)\n",
        "signal_stereo = [signal_left, signal_right]\n",
        "ipd.Audio(data=signal_stereo, rate=fs)"
      ],
      "metadata": {
        "id": "ITHw3oVF27uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Objects"
      ],
      "metadata": {
        "id": "mnySS4yC3utJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image: HTML `<img>` tag**\n",
        "\n",
        "Similar to audio, there are many ways to integrate image objects into a Jupyter notebook. First of all, one can use the [`<img>` tag](https://www.w3schools.com/Tags/tag_img.asp) within a markdown cell without requring any Python. The following figure shows a self-similarity matrix (SSM) of a recording of Brahms' Hungarian Dance No. 5, see Section 4.2.2 of <a href=\"http://www.music-processing.de/\">[MÃ¼ller, FMP, Springer 2015].</a>\n",
        "\n",
        "<img src=\"https://github.com/rahiakela/audio-processing-research-and-practice/blob/main/fundamentals-of-music-processing/01-basics/data/FMP_B_Brahms-SSM.png?raw=1\" width=\"300px\" align=\"middle\" alt=\"C0\">\n",
        "\n",
        "HTML also allows for showing animated GIFs. This simple format encodes a number of images or frames, which are presented in a specific order to create a short animation. Using animated GIFs is a nice way to illustrate processing pipelines. For example, the following animated GIF shows the previous SSM in its original form along with a version after applying smoothing as well as thresholding and scaling.\n",
        "\n",
        "<img src=\"https://github.com/rahiakela/audio-processing-research-and-practice/blob/main/fundamentals-of-music-processing/01-basics/data/FMP_B_Brahms-SSM.gif?raw=1\" width=\"300px\" alt=\"SSM\">"
      ],
      "metadata": {
        "id": "BBZCfLK63vkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image: Using  <code>IPython.display.Image</code>"
      ],
      "metadata": {
        "id": "PzQf2d0r5Gk8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to the the audio case, an alternative is to use the module <code>IPython.display</code> to create an image given the path to a PNG/JPEG/GIF file. As for images, the following class is available:\n",
        "\n",
        "`IPython.display.Image(data=None, url=None, filename=None, format=None, embed=None, width=None, height=None, retina=False, unconfined=False, metadata=None)`\n",
        "\n",
        "Again, there are two options, which either embed or link an image object:\n",
        "\n",
        "* When using the keyword argument `filename`, the image file is loaded from the specified path and **embedded** into the notebook (with default `embed=True`). \n",
        "* When using the keyword argument `url`, the data is **linked** by the specified URL (with default `embed=False`). \n",
        "\n",
        "Here are some examples:"
      ],
      "metadata": {
        "id": "oi93n75D5HQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Kmy2aXC4_lf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}